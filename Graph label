In your code, there are a few adjustments you could make to ensure clarity and accuracy:

Fix column access for Loss Amount: In the second plot, you’re trying to access 'Loss Amount' by ('Loss Amount', 'sum'), which would only be necessary if the data had a MultiIndex. To fix this, verify the column name and use it directly.
Add labels to the bar plot: I’ll also add instructions to label each bar with its Loss Amount value for readability.
Here’s the revised code with these enhancements:

python
Copy code
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Sample dummy data setup (as a reference; replace with actual data)
dummy_data = pd.DataFrame({
    'Date': pd.date_range(start='2020-01-01', periods=100, freq='D'),
    'Loss Amount': np.random.uniform(1000, 5000, 100),
    'Event Count': np.random.randint(1, 5, 100)
})

grouped_summary = pd.DataFrame({
    'Business Line': ['Retail', 'Corporate Banking', 'Investment Banking', 'Insurance', 
                      'Wealth Management', 'Asset Management', 'Private Banking'],
    'Event Type': ['Fraud', 'System Failure', 'Theft', 'Compliance', 
                   'Natural Disaster', 'Cyber Attack', 'Market Risk'],
    'Loss Amount': [10000, 25000, 35000, 12000, 15000, 18000, 16000]
})

# Setting up plots for time-based analysis
plt.figure(figsize=(16, 10))

# Plotting average loss amount over time
plt.subplot(2, 1, 1)
dummy_data.set_index('Date').resample('M')['Loss Amount'].mean().plot(color='purple', marker='o')
plt.title('Average Monthly Loss Amount Over Time')
plt.ylabel('Loss Amount')

# Plotting event frequency over time
plt.subplot(2, 1, 2)
dummy_data.set_index('Date').resample('M')['Event Count'].sum().plot(color='teal', marker='o')
plt.title('Total Event Count Over Time')
plt.ylabel('Event Count')
plt.xlabel('Date')

plt.tight_layout()
plt.show()

# Visualizing total loss amount by business line and event type
plt.figure(figsize=(14, 8))
bar_plot = sns.barplot(data=grouped_summary, x='Business Line', y='Loss Amount', hue='Event Type')
plt.title('Total Loss Amount by Business Line and Event Type')
plt.ylabel('Total Loss Amount')
plt.yscale('log')  # Log scale due to skewness

# Adding labels on top of each bar
for p in bar_plot.patches:
    bar_plot.annotate(
        f'{p.get_height():,.0f}',  # format to comma-separated values with no decimals
        (p.get_x() + p.get_width() / 2., p.get_height()),  # positioning the label at the bar's center
        ha='center', va='bottom',  # alignment for horizontal and vertical
        xytext=(0, 5),  # offset label slightly above the bar
        textcoords='offset points',
        fontsize=10,
        color='black'
    )

plt.show()
Explanation of the Changes:
Corrected Column Access: Access Loss Amount in grouped_summary without needing a tuple.
Labeling Each Bar in Bar Plot: This will help clarify each bar’s exact Loss Amount value.
Subplot Layout and Label Adjustments: The tight_layout() function improves spacing, especially when adding labels.
This updated code will give you time series plots with average monthly loss and event counts, and a labeled bar plot for business lines and event types.






You said:
value counts label
ChatGPT said:
ChatGPT
To add value counts as labels on each bar in a bar plot (for example, showing the count of occurrences for each Business Line or Event Type), you can use the value_counts() function in Pandas to calculate the counts and display these as labels on the bars.

Here's how to modify your code to include labels based on value counts:

python
Copy code
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Sample dummy data setup (adjust or replace with actual data)
dummy_data = pd.DataFrame({
    'Business Line': ['Retail', 'Corporate Banking', 'Investment Banking', 'Insurance', 
                      'Wealth Management', 'Asset Management', 'Private Banking', 'Retail'],
    'Event Type': ['Fraud', 'System Failure', 'Theft', 'Compliance', 
                   'Natural Disaster', 'Cyber Attack', 'Market Risk', 'Fraud']
})

# Calculate the counts for each Business Line
business_line_counts = dummy_data['Business Line'].value_counts().reset_index()
business_line_counts.columns = ['Business Line', 'Count']

# Bar plot for Business Line counts
plt.figure(figsize=(10, 6))
bar_plot = sns.barplot(data=business_line_counts, x='Business Line', y='Count', color='skyblue')
plt.title('Count of Events by Business Line')
plt.ylabel('Count')

# Adding count labels on top of each bar
for p in bar_plot.patches:
    bar_plot.annotate(
        f'{int(p.get_height())}',  # format count as an integer
        (p.get_x() + p.get_width() / 2., p.get_height()),  # positioning the label at the bar's center
        ha='center', va='bottom',  # alignment for horizontal and vertical
        xytext=(0, 5),  # offset label slightly above the bar
        textcoords='offset points',
        fontsize=10,
        color='black'
    )

plt.show()
Explanation:
Value Counts Calculation: business_line_counts = dummy_data['Business Line'].value_counts().reset_index() calculates the number of occurrences for each Business Line.
Bar Plot Creation: The bar plot visualizes these counts by business line.
Labeling Bars: Each bar is annotated with its exact count using the annotate() function for clear labeling.
This method will display the counts directly on each bar, making the plot easier to interpret. If you need counts for other columns, adjust the code by replacing 'Business Line' with the desired column name.






You said:
how to add label on only spikes
ChatGPT said:
ChatGPT
To add labels only to significant spikes in your time series plots, you could label data points that exceed a certain threshold or identify peaks algorithmically. Here’s how you can do it:

Step 1: Define a Threshold or Identify Peaks
Define a threshold manually (e.g., a specific value of Loss Amount) or use a peak-finding method, like the SciPy library's find_peaks, to detect spikes automatically.

Step 2: Annotate Spikes in the Plot
Below is a code example that labels only the spikes in your average monthly loss and event count plots:

python
Copy code
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import find_peaks

# Example data generation
dates = pd.date_range(start='2020-01-01', end='2024-01-01', freq='M')
np.random.seed(0)
loss_amounts = np.random.normal(loc=500, scale=200, size=len(dates))
loss_amounts[::12] += 1000  # Artificial spikes for illustration
event_counts = np.random.poisson(lam=20, size=len(dates))
event_counts[::6] += 10  # Artificial spikes for illustration

# Create a DataFrame
dummy_data = pd.DataFrame({'Date': dates, 'Loss Amount': loss_amounts, 'Event Count': event_counts})
dummy_data.set_index('Date', inplace=True)

# Set up plot
plt.figure(figsize=(16, 10))

# Plotting average monthly loss amount over time
plt.subplot(2, 1, 1)
plt.plot(dummy_data.index, dummy_data['Loss Amount'], color='purple', marker='o', label='Loss Amount')
plt.title('Average Monthly Loss Amount Over Time')
plt.ylabel('Loss Amount')

# Identify peaks for labeling
loss_peaks, _ = find_peaks(dummy_data['Loss Amount'], height=700)  # Adjust height threshold as needed

# Annotate spikes in Loss Amount
for peak in loss_peaks:
    plt.annotate(f'{dummy_data["Loss Amount"].iloc[peak]:.2f}',
                 (dummy_data.index[peak], dummy_data["Loss Amount"].iloc[peak]),
                 xytext=(0, 10), textcoords='offset points', ha='center', color='red')

# Plotting event frequency over time
plt.subplot(2, 1, 2)
plt.plot(dummy_data.index, dummy_data['Event Count'], color='teal', marker='o', label='Event Count')
plt.title('Total Event Count Over Time')
plt.ylabel('Event Count')
plt.xlabel('Date')

# Identify peaks for event counts
event_peaks, _ = find_peaks(dummy_data['Event Count'], height=25)  # Adjust height threshold as needed

# Annotate spikes in Event Count
for peak in event_peaks:
    plt.annotate(f'{dummy_data["Event Count"].iloc[peak]}',
                 (dummy_data.index[peak], dummy_data["Event Count"].iloc[peak]),
                 xytext=(0, 10), textcoords='offset points', ha='center', color='blue')

plt.tight_layout()
plt.show()
Explanation
Spike Detection with find_peaks:

find_peaks(dummy_data['Loss Amount'], height=700) detects peaks in Loss Amount that are above 700. Adjust this height threshold based on your data.
find_peaks(dummy_data['Event Count'], height=25) similarly identifies spikes in Event Count.
Labeling Peaks:

For each detected peak, plt.annotate() places a label with the exact value slightly above the spike. The xytext=(0, 10) parameter offsets the label for clarity.
Labels are color-coded (red for Loss Amount spikes and blue for Event Count spikes) for easy identification.
Customization
Adjust the height parameter in find_peaks() to control which points are considered spikes, depending on the magnitude of your dataset. This approach keeps the plot clean by labeling only the significant spikes.






You said:
Do EDA on this data and create grapgh and add lebeling on each grapgh # Import necessary libraries
import pandas as pd
import numpy as np
import random
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# Set random seed for reproducibility
np.random.seed(42)

# Parameters for expanded dataset
n_samples = 10000  # Number of records
start_date = datetime(2015, 1, 1)
end_date = datetime(2024, 12, 31)
business_lines = ["Retail Banking", "Corporate Banking", "Wealth Management"]
event_types = ["Fraud", "System Failure", "Legal Risk", "External Fraud", "Process Failure"]

# Generate random dates within the range
date_range = pd.date_range(start=start_date, end=end_date, periods=n_samples)

# Generate random business lines, event types, event counts, and loss amounts
business_line_data = np.random.choice(business_lines, size=n_samples)
event_type_data = np.random.choice(event_types, size=n_samples)
event_count_data = np.random.poisson(lam=5, size=n_samples)  # Poisson distribution for frequency
loss_amount_data = np.random.lognormal(mean=10, sigma=2, size=n_samples)  # Log-Normal for severity

# Generate event descriptions
event_description_data = [
    f"{event_type} occurred in {business_line} sector, impacting operations." 
    for event_type, business_line in zip(event_type_data, business_line_data)
]

# Create DataFrame
expanded_data = pd.DataFrame({
    'Date': date_range,
    'Business Line': business_line_data,
    'Event Type': event_type_data,
    'Event Count': event_count_data,
    'Loss Amount': loss_amount_data,
    'Event Description': event_description_data
})

# Display the first few rows
print(expanded_data.head())
ChatGPT said:
ChatGPT
To perform EDA on this dataset and create labeled visualizations, let’s analyze different aspects, such as distribution of Loss Amount and Event Count, frequency of events by Business Line and Event Type, and trends over time.

Here’s a step-by-step approach with example plots and annotations.

Step 1: Import Necessary Libraries
Ensure all libraries are imported:

python
Copy code
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
Step 2: Summary of the Dataset
Check for any missing values and obtain basic statistics:

python
Copy code
print(expanded_data.isnull().sum())  # Check for missing values
print(expanded_data.describe())      # Summary statistics
Step 3: Event Frequency by Business Line and Event Type
Count of Events by Business Line:

python
Copy code
plt.figure(figsize=(10, 6))
sns.countplot(data=expanded_data, x='Business Line', palette="Set2")
plt.title('Event Frequency by Business Line')
plt.xlabel('Business Line')
plt.ylabel('Event Count')
for index, value in enumerate(expanded_data['Business Line'].value_counts()):
    plt.text(index, value, str(value), ha='center', va='bottom')  # Adding labels
plt.show()
Count of Events by Event Type:

python
Copy code
plt.figure(figsize=(10, 6))
sns.countplot(data=expanded_data, x='Event Type', palette="Set1")
plt.title('Event Frequency by Event Type')
plt.xlabel('Event Type')
plt.ylabel('Event Count')
for index, value in enumerate(expanded_data['Event Type'].value_counts()):
    plt.text(index, value, str(value), ha='center', va='bottom')  # Adding labels
plt.show()
Step 4: Distribution of Loss Amount
Since Loss Amount is log-normally distributed, a log scale can clarify the visualization.

python
Copy code
plt.figure(figsize=(10, 6))
sns.histplot(expanded_data['Loss Amount'], bins=50, kde=True, color='orange')
plt.xscale('log')
plt.title('Distribution of Loss Amount (Log Scale)')
plt.xlabel('Loss Amount (Log Scale)')
plt.ylabel('Frequency')
plt.show()
Step 5: Average Monthly Loss and Event Count Over Time
Resample Data to Monthly Frequency:

python
Copy code
expanded_data['Date'] = pd.to_datetime(expanded_data['Date'])
monthly_data = expanded_data.resample('M', on='Date').agg({
    'Loss Amount': 'mean',
    'Event Count': 'sum'
})
Plot Average Monthly Loss Amount:

python
Copy code
plt.figure(figsize=(14, 6))
plt.plot(monthly_data.index, monthly_data['Loss Amount'], color='purple', marker='o')
plt.title('Average Monthly Loss Amount Over Time')
plt.xlabel('Date')
plt.ylabel('Average Loss Amount')
plt.xticks(rotation=45)

# Adding labels to peaks
for x, y in zip(monthly_data.index, monthly_data['Loss Amount']):
    if y > monthly_data['Loss Amount'].quantile(0.95):  # Annotate top 5% peaks
        plt.text(x, y, f'{y:.2f}', ha='center', va='bottom', color='black')
plt.show()
Plot Total Monthly Event Count:

python
Copy code
plt.figure(figsize=(14, 6))
plt.plot(monthly_data.index, monthly_data['Event Count'], color='teal', marker='o')
plt.title('Total Monthly Event Count Over Time')
plt.xlabel('Date')
plt.ylabel('Total Event Count')
plt.xticks(rotation=45)

# Adding labels to peaks
for x, y in zip(monthly_data.index, monthly_data['Event Count']):
    if y > monthly_data['Event Count'].quantile(0.95):  # Annotate top 5% peaks
        plt.text(x, y, f'{y}', ha='center', va='bottom', color='black')
plt.show()
Step 6: Total Loss by Business Line and Event Type
Group Data by Business Line and Event Type:

python
Copy code
grouped_data = expanded_data.groupby(['Business Line', 'Event Type']).agg({
    'Loss Amount': 'sum'
}).reset_index()
Bar Plot for Total Loss by Business Line and Event Type:

python
Copy code
plt.figure(figsize=(12, 8))
sns.barplot(data=grouped_data, x='Business Line', y='Loss Amount', hue='Event Type', palette='viridis')
plt.title('Total Loss Amount by Business Line and Event Type')
plt.xlabel('Business Line')
plt.ylabel('Total Loss Amount')
plt.yscale('log')  # Use log scale for clarity
for index, row in grouped_data.iterrows():
    plt.text(index, row['Loss Amount'], f'{row["Loss Amount"]:.2f}', ha='center', va='bottom')
plt.show()
Summary
This EDA provides a comprehensive overview of the data, focusing on key features like Business Line, Event Type, Loss Amount, and Event Count. The visualizations, with labeled peaks and values, help identify patterns and outliers, making it easier to communicate findings in a business-friendly format.






You said:
Please write entire code in single window
ChatGPT said:
ChatGPT
Here’s the entire EDA code in a single code block, with comments explaining each part:

python
Copy code
# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# Set random seed for reproducibility
np.random.seed(42)

# Parameters for expanded dataset
n_samples = 10000  # Number of records
start_date = datetime(2015, 1, 1)
end_date = datetime(2024, 12, 31)
business_lines = ["Retail Banking", "Corporate Banking", "Wealth Management"]
event_types = ["Fraud", "System Failure", "Legal Risk", "External Fraud", "Process Failure"]

# Generate random dates within the range
date_range = pd.date_range(start=start_date, end=end_date, periods=n_samples)

# Generate random business lines, event types, event counts, and loss amounts
business_line_data = np.random.choice(business_lines, size=n_samples)
event_type_data = np.random.choice(event_types, size=n_samples)
event_count_data = np.random.poisson(lam=5, size=n_samples)  # Poisson distribution for frequency
loss_amount_data = np.random.lognormal(mean=10, sigma=2, size=n_samples)  # Log-Normal for severity

# Generate event descriptions
event_description_data = [
    f"{event_type} occurred in {business_line} sector, impacting operations." 
    for event_type, business_line in zip(event_type_data, business_line_data)
]

# Create DataFrame
expanded_data = pd.DataFrame({
    'Date': date_range,
    'Business Line': business_line_data,
    'Event Type': event_type_data,
    'Event Count': event_count_data,
    'Loss Amount': loss_amount_data,
    'Event Description': event_description_data
})

# Summary of dataset
print(expanded_data.isnull().sum())  # Check for missing values
print(expanded_data.describe())      # Summary statistics

# Event Frequency by Business Line
plt.figure(figsize=(10, 6))
sns.countplot(data=expanded_data, x='Business Line', palette="Set2")
plt.title('Event Frequency by Business Line')
plt.xlabel('Business Line')
plt.ylabel('Event Count')
for index, value in enumerate(expanded_data['Business Line'].value_counts()):
    plt.text(index, value, str(value), ha='center', va='bottom')  # Adding labels
plt.show()

# Event Frequency by Event Type
plt.figure(figsize=(10, 6))
sns.countplot(data=expanded_data, x='Event Type', palette="Set1")
plt.title('Event Frequency by Event Type')
plt.xlabel('Event Type')
plt.ylabel('Event Count')
for index, value in enumerate(expanded_data['Event Type'].value_counts()):
    plt.text(index, value, str(value), ha='center', va='bottom')  # Adding labels
plt.show()

# Distribution of Loss Amount
plt.figure(figsize=(10, 6))
sns.histplot(expanded_data['Loss Amount'], bins=50, kde=True, color='orange')
plt.xscale('log')
plt.title('Distribution of Loss Amount (Log Scale)')
plt.xlabel('Loss Amount (Log Scale)')
plt.ylabel('Frequency')
plt.show()

# Resample Data to Monthly Frequency for time-based analysis
expanded_data['Date'] = pd.to_datetime(expanded_data['Date'])
monthly_data = expanded_data.resample('M', on='Date').agg({
    'Loss Amount': 'mean',
    'Event Count': 'sum'
})

# Average Monthly Loss Amount Over Time
plt.figure(figsize=(14, 6))
plt.plot(monthly_data.index, monthly_data['Loss Amount'], color='purple', marker='o')
plt.title('Average Monthly Loss Amount Over Time')
plt.xlabel('Date')
plt.ylabel('Average Loss Amount')
plt.xticks(rotation=45)
# Adding labels to peaks
for x, y in zip(monthly_data.index, monthly_data['Loss Amount']):
    if y > monthly_data['Loss Amount'].quantile(0.95):  # Annotate top 5% peaks
        plt.text(x, y, f'{y:.2f}', ha='center', va='bottom', color='black')
plt.show()

# Total Monthly Event Count Over Time
plt.figure(figsize=(14, 6))
plt.plot(monthly_data.index, monthly_data['Event Count'], color='teal', marker='o')
plt.title('Total Monthly Event Count Over Time')
plt.xlabel('Date')
plt.ylabel('Total Event Count')
plt.xticks(rotation=45)
# Adding labels to peaks
for x, y in zip(monthly_data.index, monthly_data['Event Count']):
    if y > monthly_data['Event Count'].quantile(0.95):  # Annotate top 5% peaks
        plt.text(x, y, f'{y}', ha='center', va='bottom', color='black')
plt.show()

# Group Data by Business Line and Event Type for Total Loss Analysis
grouped_data = expanded_data.groupby(['Business Line', 'Event Type']).agg({
    'Loss Amount': 'sum'
}).reset_index()

# Total Loss by Business Line and Event Type
plt.figure(figsize=(12, 8))
sns.barplot(data=grouped_data, x='Business Line', y='Loss Amount', hue='Event Type', palette='viridis')
plt.title('Total Loss Amount by Business Line and Event Type')
plt.xlabel('Business Line')
plt.ylabel('Total Loss Amount')
plt.yscale('log')  # Log scale for clarity
for index, row in grouped_data.iterrows():
    plt.text(index, row['Loss Amount'], f'{row["Loss Amount"]:.2f}', ha='center', va='bottom')
plt.show()
This code performs the following:

Creates a sample dataset with business and event-related columns.
Shows summary statistics and missing value checks.
Analyzes event frequencies and distributions of losses.
Resamples data to show monthly trends for average losses and event counts.
Aggregates loss amounts by business line and event type and visualizes it using bar plots. Labels are added for peaks and values, providing clarity in each plot.





You said:
value coynts label
ChatGPT said:
ChatGPT
To add labels showing the counts of each category on a bar plot using value_counts, you can plot the counts directly and then annotate the count on each bar. Here’s how you can do it:

python
Copy code
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Sample Data (if needed to recreate)
np.random.seed(42)
n_samples = 1000
data = pd.DataFrame({
    'Category': np.random.choice(['A', 'B', 'C', 'D'], size=n_samples)
})

# Get counts
value_counts = data['Category'].value_counts()

# Create bar plot with counts
plt.figure(figsize=(8, 6))
sns.barplot(x=value_counts.index, y=value_counts.values, palette="Set2")
plt.title('Category Counts')
plt.xlabel('Category')
plt.ylabel('Counts')

# Add count labels on top of each bar
for index, value in enumerate(value_counts.values):
    plt.text(index, value, str(value), ha='center', va='bottom')

plt.show()
Explanation:
value_counts calculates the count of each category.
sns.barplot creates a bar plot from these counts.
plt.text adds labels above each bar, positioning them using the index and value of each bar. The ha='center' and va='bottom' align the text correctly on the bars.



############################################################
To create a graph of Net Loss by Event Counts and Business Line, we'll use a scatter plot with Event Count on the x-axis, Net Loss Amount on the y-axis, and different colors for each Business Line. This visualization will help you see the relationship between event frequency and the associated financial impact, segmented by business line.

Here’s the complete code for generating the dataset and plotting:

python
Copy code
# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# Set random seed for reproducibility
np.random.seed(42)

# Parameters for expanded dataset
n_samples = 10000  # Number of records
start_date = datetime(2015, 1, 1)
end_date = datetime(2024, 12, 31)
business_lines = ["Retail Banking", "Corporate Banking", "Wealth Management"]
event_types = ["Fraud", "System Failure", "Legal Risk", "External Fraud", "Process Failure"]

# Generate random dates within the range
date_range = pd.date_range(start=start_date, end=end_date, periods=n_samples)

# Generate random business lines, event types, event counts, and loss amounts
business_line_data = np.random.choice(business_lines, size=n_samples)
event_type_data = np.random.choice(event_types, size=n_samples)
event_count_data = np.random.poisson(lam=5, size=n_samples)  # Poisson distribution for frequency
loss_amount_data = np.random.lognormal(mean=10, sigma=2, size=n_samples)  # Log-Normal for severity

# Create DataFrame
expanded_data = pd.DataFrame({
    'Date': date_range,
    'Business Line': business_line_data,
    'Event Type': event_type_data,
    'Event Count': event_count_data,
    'Net Loss Amount': loss_amount_data
})

# Plot Net Loss by Event Counts and Business Line
plt.figure(figsize=(12, 8))
sns.scatterplot(data=expanded_data, x='Event Count', y='Net Loss Amount', hue='Business Line', alpha=0.6)
plt.yscale('log')  # Log scale for better visualization if values are skewed
plt.title('Net Loss Amount by Event Counts and Business Line')
plt.xlabel('Event Count')
plt.ylabel('Net Loss Amount')

# Display plot
plt.legend(title='Business Line')
plt.show()
Explanation
Dataset: Generates a synthetic dataset with event count and loss amount per business line.
Plot: Uses a scatter plot to show each Business Line in a different color.
Log Scale: Applied on the y-axis for Net Loss Amount if the values are highly skewed, as often seen with financial loss data.





You said:
i need line chart
ChatGPT said:
ChatGPT
A line chart is suitable for visualizing trends over time. We can modify the previous code to plot a line chart of Net Loss Amount over time, grouped by Business Line.

Here's the code to create a time-series line chart that shows how net losses change over time for each business line:

python
Copy code
# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

# Set random seed for reproducibility
np.random.seed(42)

# Parameters for expanded dataset
n_samples = 10000  # Number of records
start_date = datetime(2015, 1, 1)
end_date = datetime(2024, 12, 31)
business_lines = ["Retail Banking", "Corporate Banking", "Wealth Management"]
event_types = ["Fraud", "System Failure", "Legal Risk", "External Fraud", "Process Failure"]

# Generate random dates within the range
date_range = pd.date_range(start=start_date, end=end_date, periods=n_samples)

# Generate random business lines, event types, event counts, and loss amounts
business_line_data = np.random.choice(business_lines, size=n_samples)
event_type_data = np.random.choice(event_types, size=n_samples)
event_count_data = np.random.poisson(lam=5, size=n_samples)  # Poisson distribution for frequency
loss_amount_data = np.random.lognormal(mean=10, sigma=2, size=n_samples)  # Log-Normal for severity

# Create DataFrame
expanded_data = pd.DataFrame({
    'Date': date_range,
    'Business Line': business_line_data,
    'Event Type': event_type_data,
    'Event Count': event_count_data,
    'Net Loss Amount': loss_amount_data
})

# Aggregate data by month and business line for plotting
expanded_data['Month'] = expanded_data['Date'].dt.to_period('M')
monthly_losses = expanded_data.groupby(['Month', 'Business Line'])['Net Loss Amount'].sum().reset_index()
monthly_losses['Month'] = monthly_losses['Month'].dt.to_timestamp()  # Convert to timestamp for plotting

# Plot line chart of Net Loss Amount over time by Business Line
plt.figure(figsize=(14, 8))
for line in business_lines:
    subset = monthly_losses[monthly_losses['Business Line'] == line]
    plt.plot(subset['Month'], subset['Net Loss Amount'], marker='o', label=line)

# Add labels and title
plt.title('Monthly Net Loss Amount Over Time by Business Line')
plt.xlabel('Date')
plt.ylabel('Net Loss Amount')
plt.yscale('log')  # Log scale due to skewness in financial data
plt.legend(title='Business Line')

# Show plot
plt.show()
Explanation
Data Aggregation: The data is aggregated by Month and Business Line to calculate the total Net Loss Amount per month.
Line Chart: A line is plotted for each business line, showing the trend of net loss over time.
Log Scale: Applied on the y-axis to better handle skewed loss data.
This line chart will display monthly net loss trends for each business line over the specified date range. Each line represents a different business line, with markers at each month for clarity.






You said:
add label also
ChatGPT said:
ChatGPT
To add labels on the line chart for specific data points, you can annotate each line with the corresponding values at key points (e.g., for the last data point or for notable peaks). Here's the updated code with labels added to the chart:

python
Copy code
# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

# Set random seed for reproducibility
np.random.seed(42)

# Parameters for expanded dataset
n_samples = 10000  # Number of records
start_date = datetime(2015, 1, 1)
end_date = datetime(2024, 12, 31)
business_lines = ["Retail Banking", "Corporate Banking", "Wealth Management"]
event_types = ["Fraud", "System Failure", "Legal Risk", "External Fraud", "Process Failure"]

# Generate random dates within the range
date_range = pd.date_range(start=start_date, end=end_date, periods=n_samples)

# Generate random business lines, event types, event counts, and loss amounts
business_line_data = np.random.choice(business_lines, size=n_samples)
event_type_data = np.random.choice(event_types, size=n_samples)
event_count_data = np.random.poisson(lam=5, size=n_samples)  # Poisson distribution for frequency
loss_amount_data = np.random.lognormal(mean=10, sigma=2, size=n_samples)  # Log-Normal for severity

# Create DataFrame
expanded_data = pd.DataFrame({
    'Date': date_range,
    'Business Line': business_line_data,
    'Event Type': event_type_data,
    'Event Count': event_count_data,
    'Net Loss Amount': loss_amount_data
})

# Aggregate data by month and business line for plotting
expanded_data['Month'] = expanded_data['Date'].dt.to_period('M')
monthly_losses = expanded_data.groupby(['Month', 'Business Line'])['Net Loss Amount'].sum().reset_index()
monthly_losses['Month'] = monthly_losses['Month'].dt.to_timestamp()  # Convert to timestamp for plotting

# Plot line chart of Net Loss Amount over time by Business Line
plt.figure(figsize=(14, 8))
for line in business_lines:
    subset = monthly_losses[monthly_losses['Business Line'] == line]
    plt.plot(subset['Month'], subset['Net Loss Amount'], marker='o', label=line)

    # Adding labels for the last data point of each line
    last_point = subset.iloc[-1]  # Get the last data point
    plt.text(last_point['Month'], last_point['Net Loss Amount'], f"{last_point['Net Loss Amount']:.2e}",
             color='black', fontsize=9, ha='left', va='bottom')

# Add labels and title
plt.title('Monthly Net Loss Amount Over Time by Business Line')
plt.xlabel('Date')
plt.ylabel('Net Loss Amount')
plt.yscale('log')  # Log scale due to skewness in financial data
plt.legend(title='Business Line')

# Show plot
plt.tight_layout()
plt.show()
Explanation of Changes:
Labeling: I've added labels on the last data point of each line (last_point = subset.iloc[-1]) by using plt.text(). This ensures that the value at the last data point of each business line is shown on the chart.
Formatting: The value is displayed in scientific notation ({last_point['Net Loss Amount']:.2e}) for easier reading of financial data.
Positioning: The text is positioned using ha='left' (horizontal alignment) and va='bottom' (vertical alignment) to ensure that the labels don't overlap with the lines.
This will show the trend of net loss over time and display the net loss values at the last point of each business line.






You said:
add label on high spikes
ChatGPT said:
ChatGPT
To add labels to high spikes in the line chart, you can find the local maxima (spikes) by detecting where the net loss amounts are significantly higher than the surrounding data points. These spikes can then be annotated with labels. Below is the updated code with annotations for high spikes (local maxima):

Updated Code:
python
Copy code
# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

# Set random seed for reproducibility
np.random.seed(42)

# Parameters for expanded dataset
n_samples = 10000  # Number of records
start_date = datetime(2015, 1, 1)
end_date = datetime(2024, 12, 31)
business_lines = ["Retail Banking", "Corporate Banking", "Wealth Management"]
event_types = ["Fraud", "System Failure", "Legal Risk", "External Fraud", "Process Failure"]

# Generate random dates within the range
date_range = pd.date_range(start=start_date, end=end_date, periods=n_samples)

# Generate random business lines, event types, event counts, and loss amounts
business_line_data = np.random.choice(business_lines, size=n_samples)
event_type_data = np.random.choice(event_types, size=n_samples)
event_count_data = np.random.poisson(lam=5, size=n_samples)  # Poisson distribution for frequency
loss_amount_data = np.random.lognormal(mean=10, sigma=2, size=n_samples)  # Log-Normal for severity

# Create DataFrame
expanded_data = pd.DataFrame({
    'Date': date_range,
    'Business Line': business_line_data,
    'Event Type': event_type_data,
    'Event Count': event_count_data,
    'Net Loss Amount': loss_amount_data
})

# Aggregate data by month and business line for plotting
expanded_data['Month'] = expanded_data['Date'].dt.to_period('M')
monthly_losses = expanded_data.groupby(['Month', 'Business Line'])['Net Loss Amount'].sum().reset_index()
monthly_losses['Month'] = monthly_losses['Month'].dt.to_timestamp()  # Convert to timestamp for plotting

# Plot line chart of Net Loss Amount over time by Business Line
plt.figure(figsize=(14, 8))
for line in business_lines:
    subset = monthly_losses[monthly_losses['Business Line'] == line]
    plt.plot(subset['Month'], subset['Net Loss Amount'], marker='o', label=line)

    # Find and label the high spikes
    for i in range(1, len(subset) - 1):  # Skip first and last points
        if subset['Net Loss Amount'].iloc[i] > subset['Net Loss Amount'].iloc[i-1] and subset['Net Loss Amount'].iloc[i] > subset['Net Loss Amount'].iloc[i+1]:
            plt.text(subset['Month'].iloc[i], subset['Net Loss Amount'].iloc[i],
                     f"{subset['Net Loss Amount'].iloc[i]:.2e}", color='red', fontsize=9, ha='center', va='bottom')

# Add labels and title
plt.title('Monthly Net Loss Amount Over Time by Business Line')
plt.xlabel('Date')
plt.ylabel('Net Loss Amount')
plt.yscale('log')  # Log scale due to skewness in financial data
plt.legend(title='Business Line')

# Show plot
plt.tight_layout()
plt.show()
Explanation of Changes:
Spike Detection: I've added a loop to identify local maxima (spikes) by checking if the current point is greater than the previous and the next point:
python
Copy code
if subset['Net Loss Amount'].iloc[i] > subset['Net Loss Amount'].iloc[i-1] and subset['Net Loss Amount'].iloc[i] > subset['Net Loss Amount'].iloc[i+1]:
Labeling: For each spike, the value is annotated with plt.text(). The labels are colored red to highlight the spikes, and the value is formatted in scientific notation ({:.2e}) for easier reading of financial figures.
Positioning: The labels are placed slightly below the spike (va='bottom') and horizontally centered above the spike (ha='center').
This will now show the line chart with labels at the high spikes, making it easy to identify unusual peaks in the data.
